name: MLOps Pipeline

on:
  push:
    branches:
      - develop

env:
  COMMIT_SHA: ${{ github.sha }}

jobs:
  train-and-deploy:
    environment: LLM
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code (để có COMMIT_SHA)
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.12
          architecture: 'x64'

      - name: Install DVC & pandas
        run: |
          pip install --upgrade pip
          pip install dvc[s3] pandas

      - name: Configure DVC remote (S3)
        run: |
          mkdir -p ~/.dvc
          cat << 'EOF' > ~/.dvc/config.local
          ['remote "s3remote"']
              url = s3://my-viet-dvc-store
              access_key_id = ${{ secrets.AWS_ACCESS_KEY_ID }}
              secret_access_key = ${{ secrets.AWS_SECRET_ACCESS_KEY }}
              region = ap-southeast-1
          EOF

      - name: DVC Pull data (train & test)
        run: |
          dvc pull -r s3remote data/SA/train.csv.dvc data/SA/test.csv.dvc

      - name: Data Validation
        run: |
          python scripts/validate_data.py --train data/SA/train.csv --test data/SA/test.csv

      - name: SSH to VAST.AI and train
        uses: appleboy/ssh-action@v0.1.7
        with:
          host: ${{ vars.VASTAI_IP }}
          username: ${{ vars.VASTAI_USER }}
          port: ${{ vars.VASTAI_PORT }}
          key: ${{ secrets.VASTAI_SSH_KEY }}
          timeout: 1800s
          command_timeout: 1800s
          envs: |
            AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}
            AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}
          script: |
            set -e

            COMMIT_SHA=$(echo ${{ github.sha }} | cut -c1-7)
            echo "Commit SHA (Short) từ GitHub Actions: ${COMMIT_SHA}"
            
            cd /workspace/ttcs/llm-mlops-pipeline
            source ./venv/bin/activate

            echo "Starting training on VAST.AI instance..."
            echo "Install dependencies"
            pip install -r requirements-train.txt

            echo "Pull latest code"
            git pull origin develop

            echo "Download data"
            dvc pull -r s3remote data/SA/train.csv.dvc data/SA/test.csv.dvc

            echo "Train model"
            # python scripts/train.py --config configs/config.yaml

            echo "Zip outputs"
            zip -r outputs_${COMMIT_SHA}.zip old-outputs

            echo "Upload to S3"
            aws s3 cp outputs_${COMMIT_SHA}.zip s3://zett-vast-ai/
            echo "Training and upload completed successfully."

      - name: SSH to EC2 and deploy
        uses: appleboy/ssh-action@v0.1.7
        with:
          host: ${{ vars.EC2_IP }}
          username: ${{ vars.EC2_USER }}
          key: ${{ secrets.EC2_SSH_KEY }}
          timeout: 1800s
          command_timeout: 1800s
          script: |
            set -e

            COMMIT_SHA=$(echo ${{ github.sha }} | cut -c1-7)
            echo "Commit SHA (Short) từ GitHub Actions: ${COMMIT_SHA}"
            
            echo "Starting deployment on EC2 instance..."
            cd /home/ubuntu/project/llm-mlops-pipeline

            echo "Pull latest code"
            git pull origin develop

            echo "Download outputs"
            aws s3 cp s3://zett-vast-ai/outputs_${COMMIT_SHA}.zip ./outputs.zip

            echo "Unzip outputs"
            unzip -o outputs.zip -d outputs

            echo "Installing dependencies..."
            pip install -r requirements-infer.txt
            
            echo "Kill existing Gradio"
            pids=$(ps -ef | grep gradio_app.py | grep -v grep | awk '{print $2}')
            if [ -n "$pids" ]; then
                kill -9 $pids
                echo "Killed Gradio app processes."
            else
                echo "No Gradio app process found."
            fi

            echo "Starting Gradio app..."
            nohup python3 gradio_app.py --model_dir ./outputs > gradio.log 2>&1 &
            disown
            echo "Gradio app started successfully."
